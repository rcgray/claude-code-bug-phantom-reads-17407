     1→# Action Plan
     2→
     3→This document contains the implementation checkboxlist for the Claude Code Phantom Reads Reproduction project. For project context and goals, see `docs/core/PRD.md`.
     4→
     5→The following are the steps for implementing the project, where the full list is split over two files:
     6→
     7→- **Action Plan Archive**: `docs/references/Action-Plan-Archive.md` - Completed phases
     8→- **Action Plan**: `docs/core/Action-Plan.md` - In-progress and future phases
     9→
    10→
    11→## Phase 0: Blocking Tasks
    12→
    13→- [x] **0.1** - Remove mentions of `/start-trial` command (see `docs/tickets/closed/update-session-analysis-spec-use-workscope-id.md`)
    14→- [x] **0.2** - Investigate reads of missing files in our pre-processing of trials (see `docs/tickets/closed/investigate-trial-data-failed-read-recording.md`)
    15→- [x] **0.3** - Add NLP assessment to trial analysis in `/update-json-data` (see `docs/tickets/closed/add-nlp-outcome-detection-to-trial-data-extraction.md`)
    16→
    17→## Phase 1: Open-Ended Investigation
    18→
    19→- [x] **1.1** - Create `docs/core/Investigation-Journal.md` and `docs/core/Experiment-Methodology-01.md`
    20→- [x] **1.2** - Collect samples of success and failure cases, store in `dev/misc/example-sessions`
    21→  - [x] **1.2.1** - Good/Bad examples for various builds (`2.0.58`, `2.0.59`, `2.0.60`, `2.1.3`, `2.1.6`)
    22→- [*] **1.3** - Examine success/failure cases to find log evidence of phantom reads
    23→  - [x] **1.3.1** - Create `docs/core/Example-Session-Analysis.md`
    24→- [x] **1.4** - Publish to Github
    25→- [x] **1.5** - Create feature plan for reproduction environment (Phase 3)
    26→
    27→## Phase 2: Explore Temporary Workarounds
    28→
    29→- [x] **2.1** - Brainstorm ideas and draft `docs/core/Possible-Workarounds.md`
    30→- [x] **2.2** - Test "Warning in Onboarding" approach
    31→- [x] **2.3** - Test "PostToolUse Detection Hook" approach
    32→- [-] **2.4** - Test "Proof-of-Work Verification" approach
    33→- [x] **2.5** - Test "PreToolUse Read Override" approach
    34→- [x] **2.6** - Test "MCP Server Replacement" approach - SUCCESS
    35→  - [x] **2.6.1** - Create `WORKAROUNDS.md` file
    36→
    37→## Phase 3: Reproduction Environment - Three Specs
    38→
    39→- [x] **3.1** - Create Reproduction-Specs-Collection feature (see `docs/features/reproduction-specs-collection/Reproduction-Specs-Collection-Overview.md`)
    40→Collect-Trials-Script-Overview.md`)
    41→- [x] **3.2** - Execute manual reproduction trial of the three specs created in previous Phase
    42→  - [x] **3.2.1** - Run `/wsd:init --custom` in a fresh Claude Code session
    43→  - [x] **3.2.2** - Run `/refine-plan` against the trigger WSDs
    44→  - [x] **3.2.3** - Prompt agent for phantom read self-report per methodology
    45→  - [x] **3.2.4** - Document results
    46→  - [x] **3.2.5** - Save chat export and session `.jsonl` files in `dev/misc/self-examples`
    47→- [x] **3.4** - Evaluate reproduction sufficiency
    48→  - [x] **3.4.1** - Assess whether phantom reads occurred in the trials where they were expected
    49→- [x] **3.5** - Update Documentation
    50→  - [x] **3.5.1** - Ensure that `docs/core/Investigation-Journal.md` records the approach and results of Reproduction-Specs-Collection investigation
    51→  - [x] **3.5.2** - Update `README.md` to reflect our current understanding of the issue and include directions on end-users running their own tests.
    52→  - [x] **3.5.3** - Ensure that there is a clear `docs/core/Experiment-Methodology-#.md` that matches the most recent experiments run
    53→
    54→## Phase 4: Analysis Tools
    55→
    56→- [x] **4.1** - Create the `cc_version.py` script (see `docs/features/cc-version-script/CC-Version-Script-Overview.md`)
    57→- [x] **4.2** - Create the `collect_trials.py` script (see `docs/features/collect-trials-script/Collect-Trials-Script-Overview.md`)
    58→- [x] **4.3** - Design and create analysis scripts feature
    59→- [x] **4.4** - Run sample experiments as we would expect end-users to run them. Evaluate analysis scripts results.
    60→- [ ] **4.5** - Create a tool for generating the `file_token_counts.json` file for collections (see `docs/features/update-file-summary/Update-File-Summary-Overview.md`)
    61→- [ ] **4.5** - Update Documentation
    62→  - [ ] **4.5.1** - Ensure that `docs/core/Investigation-Journal.md` records the approach and results of our Analysis Scripts.
    63→  - [ ] **4.5.2** - Update `README.md` to reflect our current understanding of the issue and include directions on end-users running their own tests AND new analysis tools
    64→  - [ ] **4.5.3** - Ensure that there is a clear `docs/core/Experiment-Methodology-#.md` that matches the most recent experiments run.
    65→
    66→
    67→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
